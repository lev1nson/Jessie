# Story 1.5: Обработка вложений и векторизация

## Status
Draft

## Story
**As a** система,
**I want** извлекать текст из вложений, объединять его с текстом письма и сохранять в виде векторов,
**so that** весь контент был доступен для семантического поиска.

## Acceptance Criteria
1. Текст успешно извлекается из вложений .pdf и .docx.
2. Извлеченный текст и текст письма объединяются.
3. Объединенный текст преобразуется в векторы и сохраняется в векторной базе данных.

## Tasks / Subtasks
- [ ] Task 1: Интеграция с LLM сервисом (AC: 3)
  - [ ] Настроить подключение к OpenAI API
  - [ ] Создать сервис для генерации embeddings
  - [ ] Настроить обработку ошибок LLM API
  - [ ] Добавить retry логику для временных ошибок
- [ ] Task 2: Реализация извлечения текста из вложений (AC: 1)
  - [ ] Интегрировать PDF парсер (pdf-parse или pdf2pic)
  - [ ] Интегрировать DOCX парсер (mammoth или docx)
  - [ ] Добавить обработку ошибок парсинга
  - [ ] Реализовать fallback логику для поврежденных файлов
- [ ] Task 3: Объединение и подготовка текста (AC: 2)
  - [ ] Создать логику объединения текста письма и вложений
  - [ ] Реализовать очистку и нормализацию текста
  - [ ] Добавить разбиение больших текстов на чанки
  - [ ] Настроить ограничения по размеру для LLM API
- [ ] Task 4: Векторизация и сохранение (AC: 3)
  - [ ] Создать сервис для генерации embeddings
  - [ ] Интегрировать с pgvector в Supabase
  - [ ] Реализовать batch сохранение векторов
  - [ ] Добавить индексы для оптимизации поиска
- [ ] Task 5: Оптимизация производительности (AC: 1, 2, 3)
  - [ ] Реализовать асинхронную обработку вложений
  - [ ] Добавить кэширование результатов парсинга
  - [ ] Оптимизировать размер чанков для векторизации
  - [ ] Настроить очередь задач для больших файлов
- [ ] Task 6: Тестирование системы векторизации (AC: 1, 2, 3)
  - [ ] Создать unit тесты для парсеров вложений
  - [ ] Создать тесты для LLM сервиса
  - [ ] Создать integration тесты для полного процесса
  - [ ] Тестирование производительности векторизации

## Dev Notes

### Previous Story Insights
[Source: docs/stories/1.4.content-filtering.story.md]
- Система фильтрации писем настроена
- Парсеры для HTML, PDF и DOCX созданы
- Базовая структура для обработки вложений

### Data Models
[Source: docs/architecture/database-schema.md]
- Использовать таблицу `public.emails`:
  - Добавить поле `embedding` (VECTOR(1536))
  - Добавить поле `text_chunks` (JSONB) для хранения чанков
  - Добавить поле `vectorized_at` (TIMESTAMPTZ)
- Создать индекс: `CREATE INDEX ON public.emails USING hnsw (embedding vector_cosine_ops)`

### API Specifications
[Source: docs/architecture/external-apis.md]
- Использовать OpenAI API для генерации embeddings
- Endpoint: /v1/embeddings
- Модель: text-embedding-3-small (1536 dimensions)
- Поддержка batch запросов для оптимизации

### Component Specifications
[Source: docs/architecture/tech-stack.md]
- Векторное хранилище: pgvector ~0.7
- LLM Provider: OpenAI API
- Асинхронная обработка: Node.js streams и queues

### File Locations
[Source: docs/architecture/project-structure.md]
```
apps/web/
├── lib/
│   ├── llm/
│   │   ├── openaiClient.ts
│   │   ├── embeddingService.ts
│   │   └── textProcessor.ts
│   ├── parsers/
│   │   ├── pdfParser.ts
│   │   └── docxParser.ts
│   └── repositories/
│       └── emailRepository.ts
packages/lib/
├── supabaseClient.ts
└── types.ts
```

### Testing Requirements
[Source: docs/architecture/testing-strategy.md]
- **Unit тесты**: Vitest для парсеров и LLM сервиса
- **Integration тесты**: Тестирование с реальными файлами и OpenAI API
- **Performance тесты**: Тестирование векторизации больших объемов данных

### Technical Constraints
[Source: docs/architecture/coding-standards.md]
- **Строгая типизация**: Использовать типы из packages/lib/types.ts
- **Валидация данных**: Валидация результатов парсинга с помощью Zod
- **Переменные окружения**: Доступ к OpenAI API ключам через конфигурационный модуль
- **Соглашения именования**: camelCase для функций, PascalCase для классов

### Security Considerations
- **API Key Security**: Безопасное хранение OpenAI API ключей в переменных окружения, ротация ключей
- **Data Privacy**: Шифрование текстового контента перед отправкой в OpenAI API, соблюдение GDPR
- **Rate Limiting**: Ограничение запросов к OpenAI API (максимум 100 запросов в минуту)
- **Access Control**: Проверка прав доступа пользователя к API ключам
- **Error Handling**: Безопасная обработка ошибок API без раскрытия внутренней информации
- **Token Management**: Мониторинг использования токенов и предотвращение превышения лимитов

### Performance Considerations
- **OpenAI API Quota Management**: Мониторинг и управление квотами API (максимум 1000 запросов в день)
- **Vector Storage Optimization**: Оптимизация индексов pgvector для быстрого поиска
- **Batch Processing Limits**: Ограничение размера batch запросов (максимум 100 текстов за раз)
- **Memory Management**: Ограничение использования памяти при обработке больших файлов (максимум 200MB)
- **Caching Strategy**: Кэширование embeddings для повторного использования
- **Response Time**: Оптимизация времени ответа API (максимум 30 секунд на запрос)

### Testing
[Source: docs/architecture/testing-strategy.md]
- **Парсер тесты**: Создать тесты для pdfParser и docxParser
- **LLM тесты**: Создать тесты для embeddingService
- **Integration тесты**: Тестирование полного процесса векторизации
- **Performance тесты**: Тестирование обработки больших файлов

## Change Log
| Date | Version | Description | Author |
| :---- | :---- | :---- | :---- |
| 24.07.2025 | 1.0 | Создание истории | Bob (SM) |
| 24.07.2025 | 1.1 | Добавление разделов безопасности и производительности vectorization | Bob (SM) |

## Dev Agent Record

### Agent Model Used
*Заполняется разработчиком*

### Debug Log References
*Заполняется разработчиком*

### Completion Notes List
*Заполняется разработчиком*

### File List
*Заполняется разработчиком*

## QA Results
*Заполняется QA агентом* 