# Story 4.3: ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ chat API Ðº vector search

## Status
Ready for Development

## Story
**As a** Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ,
**I want** Ð¿Ð¾Ð»ÑƒÑ‡Ð°Ñ‚ÑŒ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼Ð¾Ð¸Ñ… Ð¿Ð¸ÑÐµÐ¼ Ñ‡ÐµÑ€ÐµÐ· chat interface,
**so that** Ñ Ð¼Ð¾Ð³ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ²Ð¾Ð¹ email Ð°Ñ€Ñ…Ð¸Ð² Ñ‡ÐµÑ€ÐµÐ· Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€ Ñ Jessie.

## Acceptance Criteria
1. Chat API Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ real vector search Ð²Ð¼ÐµÑÑ‚Ð¾ mock data
2. Search results Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ñ‹ Ð½Ð° user's emails Ñ proper data isolation
3. LLM responses Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… email content
4. Chat interface Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ source emails Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
5. Performance: Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð² Ñ‚ÐµÑ‡ÐµÐ½Ð¸Ðµ 3 ÑÐµÐºÑƒÐ½Ð´

## ðŸš€ **QUICK START**
Before starting, review: **docs/DEVELOPER_QUICK_REFERENCE.md** for essential commands and checklists.

## Tasks / Subtasks

### Task 1: Replace Mock Data Ñ Real Vector Search (AC: 1)
- [ ] ÐœÐ¾Ð´Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ `/api/chat/messages/route.ts`
- [ ] **CRITICAL**: Remove ALL hardcoded mock responses from chat API
- [ ] **CRITICAL**: Verify no `return mockChatResponse()` calls remain
- [ ] **CRITICAL**: Ensure vector search called for EVERY chat message
- [ ] Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ VectorRepository Ð´Ð»Ñ semantic search
- [ ] Ð—Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ mock responses Ð½Ð° real vector search results
- [ ] Add user authentication validation Ð´Ð»Ñ API calls
- [ ] Test with user who has NO emails (empty state handling)

### Task 2: User Data Isolation (AC: 2)
- [ ] Implement user-specific vector search queries
- [ ] Add user_id filtering Ð² VectorRepository queries
- [ ] Ensure no data leakage Ð¼ÐµÐ¶Ð´Ñƒ users
- [ ] Test data isolation Ð² multi-user scenarios

### Task 3: LLM Response Generation (AC: 3)
- [ ] Integrate OpenAI/LLM service Ð´Ð»Ñ response generation
- [ ] Create prompts Ð´Ð»Ñ generating responses from email content
- [ ] Implement context window management Ð´Ð»Ñ large results
- [ ] Add fallback responses Ð´Ð»Ñ empty search results

### Task 4: Source Email Attribution (AC: 4)
- [ ] Return source email IDs Ñ each response
- [ ] Modify ChatMessages component Ð´Ð»Ñ displaying sources
- [ ] Add click handlers Ð´Ð»Ñ viewing source emails
- [ ] Implement email preview functionality

### Task 5: Performance Optimization (AC: 5)
- [ ] Optimize vector search query performance
- [ ] Implement response caching Ð´Ð»Ñ common queries
- [ ] Add parallel processing Ð³Ð´Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾
- [ ] Set reasonable timeouts Ð´Ð»Ñ all API calls

### Task 6: Enhanced Chat Experience (AC: 1-5)
- [ ] Add typing indicators Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ search/generation
- [ ] Implement streaming responses Ð´Ð»Ñ long answers
- [ ] Add error handling Ð´Ð»Ñ all failure scenarios
- [ ] Create helpful error messages Ð´Ð»Ñ users

## Dev Notes

### Current Implementation Status
- âœ… Chat API endpoints exist (Story 2.4) Ð½Ð¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽÑ‚ mock data
- âœ… VectorRepository Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½ (Story 1.5)
- âœ… ChatInterface Ð³Ð¾Ñ‚Ð¾Ð² Ð´Ð»Ñ real data
- âœ… LLM services (OpenAI client) Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹
- âŒ Integration Ð¼ÐµÐ¶Ð´Ñƒ chat API Ð¸ vector search Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚
- âŒ Source attribution Ð½Ðµ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½

### Integration Architecture
```typescript
// Modified /api/chat/messages/route.ts
export async function POST(request: Request) {
  const { chatId, content } = await request.json()
  const user = await getCurrentUser()
  
  // 1. Perform vector search
  const searchResults = await vectorRepository.findSimilar(
    content, 
    { userId: user.id, limit: 5, threshold: 0.7 }
  )
  
  // 2. Generate LLM response
  const response = await llmService.generateResponse(
    content, 
    searchResults
  )
  
  // 3. Save and return message with sources
  const message = await messageRepository.save({
    chatId,
    role: 'assistant',
    content: response.text,
    sourceEmailIds: searchResults.map(r => r.emailId)
  })
  
  return { message, sources: searchResults }
}
```

### File Locations
```
apps/web/app/api/chat/messages/route.ts              # Main integration point
apps/web/lib/repositories/vectorRepository.ts        # Existing vector search
apps/web/lib/llm/openaiClient.ts                    # Existing LLM client
apps/web/components/features/chat/ChatMessages.tsx   # UI updates needed
apps/web/components/features/chat/MessageItem.tsx    # Source display
```

### Required API Modifications

#### 1. Vector Search Integration
```typescript
// Replace mock data with real search
const searchResults = await vectorRepository.findSimilar(query, {
  userId: user.id,
  limit: 5,
  threshold: 0.7,
  includeMetadata: true
})
```

#### 2. LLM Response Generation
```typescript
async function generateContextualResponse(
  query: string, 
  emailContext: SearchResult[]
): Promise<string> {
  const prompt = `
    Based on the following emails, answer the user's question: "${query}"
    
    Email Context:
    ${emailContext.map(email => `
      From: ${email.metadata.from}
      Subject: ${email.metadata.subject}
      Content: ${email.content}
    `).join('\n\n')}
    
    Answer:
  `
  
  return await openaiClient.generateResponse(prompt)
}
```

### Frontend Updates Required

#### 1. Source Email Display
```typescript
// In MessageItem.tsx, add source indicators
interface MessageWithSources {
  content: string
  sources?: EmailSource[]
}

function SourceIndicator({ sources }: { sources: EmailSource[] }) {
  return (
    <div className="mt-2 text-sm text-gray-600">
      Sources: {sources.length} emails
      {sources.map(source => (
        <button key={source.id} onClick={() => openEmailPreview(source)}>
          {source.subject}
        </button>
      ))}
    </div>
  )
}
```

#### 2. Loading States
```typescript
// Enhanced loading states for vector search
const [isSearching, setIsSearching] = useState(false)
const [isGenerating, setIsGenerating] = useState(false)

// Show "Searching emails..." then "Generating response..."
```

### Success Metrics
- [ ] 100% real data responses (no mock data)
- [ ] <3 seconds average response time
- [ ] >90% relevant search results based on user feedback
- [ ] Source attribution for 100% of responses
- [ ] No data leakage Ð¼ÐµÐ¶Ð´Ñƒ users

### API Response Format
```typescript
interface ChatResponse {
  message: {
    id: string
    content: string
    role: 'assistant'
    createdAt: string
    sourceEmailIds: string[]
  }
  sources: {
    id: string
    subject: string
    from: string
    snippet: string
    relevanceScore: number
  }[]
}
```

### Performance Targets
- Vector search: <1 second for 1000+ emails
- LLM response generation: <2 seconds
- Total API response: <3 seconds
- Frontend rendering: <500ms after API response

### Error Handling Scenarios
1. **No Search Results**: "I couldn't find relevant emails for your question"
2. **Vector Search Timeout**: "Search is taking longer than expected, please try again"
3. **LLM Generation Error**: "I'm having trouble generating a response right now"
4. **Authentication Error**: Redirect to login

### ðŸ§ª **TESTING COMMANDS**

#### Test Mock Removal (CRITICAL)
```bash
# 1. Verify no mock responses remain
grep -r "mockChatResponse\|mock.*response" apps/web/app/api/chat/
# Should return: no results

# 2. Test real vector search integration
curl -X POST "https://your-app.vercel.app/api/chat/messages" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-session" \
  -d '{"chatId":"test","content":"Show me emails about project updates"}'

# 3. Verify response contains real data
# Response should include:
# - sourceEmailIds: [...] (array with email IDs, not empty)
# - message.content: (real LLM-generated response, not mock text)
```

#### Test Vector Search Functionality
```bash
# 4. Test with user who has emails
# Chat response should return relevant emails based on query

# 5. Test with user who has NO emails  
# Should return: "I couldn't find relevant emails for your question"

# 6. Test data isolation
# User A should only see responses based on User A's emails
```

#### Test Performance
```bash
# 7. Test response time
time curl -X POST "https://your-app.vercel.app/api/chat/messages" \
  -H "Content-Type: application/json" \
  -d '{"chatId":"test","content":"test query"}'
# Should complete in <3 seconds
```

### Testing Strategy
1. **Unit Tests**: Mock VectorRepository Ð² chat API tests
2. **Integration Tests**: Real search Ñ test data
3. **User Tests**: Multi-user data isolation verification  
4. **Performance Tests**: Load testing Ñ realistic query volumes
5. **E2E Tests**: Complete user journey from login to chat response
6. **Mock Removal Tests**: Verify no hardcoded responses remain

### Security Considerations
- User authentication Ð½Ð° all API endpoints
- User data isolation Ð² vector queries
- Input sanitization Ð´Ð»Ñ user queries
- Rate limiting Ð´Ð»Ñ prevent abuse
- No exposure sensitive email content Ð² logs

### Monitoring Requirements
- Query response times
- Search result relevance scores
- LLM API usage Ð¸ costs
- User satisfaction metrics
- Error rates by category

## Dependencies
- **Requires**: Story 4.2 (Vectorization integration) Ð´Ð»Ñ Ð¸Ð¼ÐµÑ‚ÑŒ vectorized data
- **Requires**: OpenAI API Ð´Ð»Ñ response generation
- **Requires**: Authenticated users Ñ email data
- **Enables**: Full MVP functionality

## Risks
- **HIGH**: Poor search relevance affects user experience
- **MEDIUM**: LLM costs may scale quickly Ñ usage
- **MEDIUM**: Performance issues Ñ large vector databases
- **LOW**: User confusion Ð±ÐµÐ· proper source attribution

### âœ… **COMPLETION VERIFICATION**

**Story 4.3 is DONE when:**
```bash
# 1. No mock responses remain
grep -r "mock" apps/web/app/api/chat/ | wc -l  # Should return: 0

# 2. Chat uses real vector search
curl -X POST "https://your-app.vercel.app/api/chat/messages" \
  -d '{"chatId":"test","content":"test"}' | jq '.sourceEmailIds | length'
# Should return: number > 0 (if user has emails)

# 3. Response time acceptable
time curl -X POST "https://your-app.vercel.app/api/chat/messages" \
  -d '{"chatId":"test","content":"test"}'
# Should complete in <3 seconds

# 4. Data isolation working
# Different users get different search results based on their emails
```

## Change Log
| Date | Version | Description | Author |
| :---- | :---- | :---- | :---- |
| 27.07.2025 | 1.0 | Story creation Ð´Ð»Ñ Epic 4 integration | Sarah (PO) |
| 27.07.2025 | 1.1 | Added mock removal checklist and testing commands | Bob (SM) |